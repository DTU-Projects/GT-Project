{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keyword Extraction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMSCMwkoc0j+I+7cEARmcbv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DTU-Projects/GT-Project/blob/main/Keyword_Extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8rDzKyIp2bL"
      },
      "source": [
        "Run it yourself: <br> https://colab.research.google.com/drive/1j8aF_AksK3YT_rfqbyPyNdYgf2nQIo-M?usp=sharing\n",
        "<br>\n",
        "Authors: Udit Chauhan and Sidharth"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aouuWc--jodX"
      },
      "source": [
        "from collections import OrderedDict\n",
        "import numpy as np\n",
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "class TextRank4Keyword():\n",
        "    \"\"\"Extract keywords from text\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.d = 0.85 # damping coefficient, usually is .85\n",
        "        self.min_diff = 1e-5 # convergence threshold\n",
        "        self.steps = 10 # iteration steps\n",
        "        self.node_weight = None # save keywords and its weight\n",
        "\n",
        "    \n",
        "    def set_stopwords(self, stopwords):  \n",
        "        \"\"\"Set stop words\"\"\"\n",
        "        for word in STOP_WORDS.union(set(stopwords)):\n",
        "            lexeme = nlp.vocab[word]\n",
        "            lexeme.is_stop = True\n",
        "    \n",
        "    def sentence_segment(self, doc, candidate_pos, lower):\n",
        "        \"\"\"Store those words only in cadidate_pos\"\"\"\n",
        "        sentences = []\n",
        "        for sent in doc.sents:\n",
        "            selected_words = []\n",
        "            for token in sent:\n",
        "                # Store words only with cadidate POS tag\n",
        "                if token.pos_ in candidate_pos and token.is_stop is False:\n",
        "                    if lower is True:\n",
        "                        selected_words.append(token.text.lower())\n",
        "                    else:\n",
        "                        selected_words.append(token.text)\n",
        "            sentences.append(selected_words)\n",
        "        return sentences\n",
        "        \n",
        "    def get_vocab(self, sentences):\n",
        "        \"\"\"Get all tokens\"\"\"\n",
        "        vocab = OrderedDict()\n",
        "        i = 0\n",
        "        for sentence in sentences:\n",
        "            for word in sentence:\n",
        "                if word not in vocab:\n",
        "                    vocab[word] = i\n",
        "                    i += 1\n",
        "        return vocab\n",
        "    \n",
        "    def get_token_pairs(self, window_size, sentences):\n",
        "        \"\"\"Build token_pairs from windows in sentences\"\"\"\n",
        "        token_pairs = list()\n",
        "        for sentence in sentences:\n",
        "            for i, word in enumerate(sentence):\n",
        "                for j in range(i+1, i+window_size):\n",
        "                    if j >= len(sentence):\n",
        "                        break\n",
        "                    pair = (word, sentence[j])\n",
        "                    if pair not in token_pairs:\n",
        "                        token_pairs.append(pair)\n",
        "        return token_pairs\n",
        "        \n",
        "    def symmetrize(self, a):\n",
        "        return a + a.T - np.diag(a.diagonal())\n",
        "    \n",
        "    def get_matrix(self, vocab, token_pairs):\n",
        "        \"\"\"Get normalized matrix\"\"\"\n",
        "        # Build matrix\n",
        "        vocab_size = len(vocab)\n",
        "        g = np.zeros((vocab_size, vocab_size), dtype='float')\n",
        "        for word1, word2 in token_pairs:\n",
        "            i, j = vocab[word1], vocab[word2]\n",
        "            g[i][j] = 1\n",
        "            \n",
        "        # Get Symmeric matrix\n",
        "        g = self.symmetrize(g)\n",
        "        \n",
        "        # Normalize matrix by column\n",
        "        norm = np.sum(g, axis=0)\n",
        "        g_norm = np.divide(g, norm, where=norm!=0) # this is ignore the 0 element in norm\n",
        "        \n",
        "        return g_norm\n",
        "\n",
        "    \n",
        "    def get_keywords(self, number=10):\n",
        "        \"\"\"Print top number keywords\"\"\"\n",
        "        node_weight = OrderedDict(sorted(self.node_weight.items(), key=lambda t: t[1], reverse=True))\n",
        "        for i, (key, value) in enumerate(node_weight.items()):\n",
        "            print(key + ' - ' + str(value))\n",
        "            if i > number:\n",
        "                break\n",
        "        \n",
        "        \n",
        "    def analyze(self, text, \n",
        "                candidate_pos=['NOUN', 'PROPN'], \n",
        "                window_size=4, lower=False, stopwords=list()):\n",
        "        \"\"\"Main function to analyze text\"\"\"\n",
        "        \n",
        "        # Set stop words\n",
        "        self.set_stopwords(stopwords)\n",
        "        \n",
        "        # Pare text by spaCy\n",
        "        doc = nlp(text)\n",
        "        \n",
        "        # Filter sentences\n",
        "        sentences = self.sentence_segment(doc, candidate_pos, lower) # list of list of words\n",
        "        \n",
        "        # Build vocabulary\n",
        "        vocab = self.get_vocab(sentences)\n",
        "        \n",
        "        # Get token_pairs from windows\n",
        "        token_pairs = self.get_token_pairs(window_size, sentences)\n",
        "        \n",
        "        # Get normalized matrix\n",
        "        g = self.get_matrix(vocab, token_pairs)\n",
        "        \n",
        "        # Initionlization for weight(pagerank value)\n",
        "        pr = np.array([1] * len(vocab))\n",
        "        \n",
        "        # Iteration\n",
        "        previous_pr = 0\n",
        "        for epoch in range(self.steps):\n",
        "            pr = (1-self.d) + self.d * np.dot(g, pr)\n",
        "            if abs(previous_pr - sum(pr))  < self.min_diff:\n",
        "                break\n",
        "            else:\n",
        "                previous_pr = sum(pr)\n",
        "\n",
        "        # Get weight for each node\n",
        "        node_weight = dict()\n",
        "        for word, index in vocab.items():\n",
        "            node_weight[word] = pr[index]\n",
        "        \n",
        "        self.node_weight = node_weight"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NylCAVZvjyXg",
        "outputId": "f32ae6a9-826e-4a83-8036-dffe6e7fb513"
      },
      "source": [
        "text = '''\n",
        "Prime Minister Narendra Modi launched the Ayushman Bharat Health Infrastructure Mission, one of the largest pan-India schemes for strengthening healthcare infrastructure, in his parliamentary constituency Varanasi in Uttar Pradesh on Monday.\n",
        "\n",
        "The Prime Minister also inaugurated various development projects worth more than â‚¹5,200 crore for his constituency.\n",
        "\n",
        "The Pradhan Mantri Ayushman Bharat Health Infrastructure Mission is one of the largest pan-India schemes for strengthening healthcare infrastructure across the country. It is in addition to the National Health Mission.\n",
        "\n",
        "Its objective is to fill gaps in public health infrastructure, especially in critical care facilities and primary care in both urban and rural areas. It will provide support for 17,788 rural health and wellness centres in 10 high-focus states. Further, 11,024 urban health and wellness centres will be established in all the States.\n",
        "\n",
        "\n",
        "Through this, critical care services will be available in all the districts of the country with more than five lakh population through exclusive critical care hospital blocks, while the remaining districts will be covered through referral services.\n",
        "\n",
        "\n",
        "People will have access to a full range of diagnostic services in the public healthcare system through a network of laboratories across the country, and integrated public health labs will be set up in all the districts.\n",
        "\n",
        "Under the scheme, a national institution for one health, four new national institutes for virology, a regional research platform for WHO South East Asia Region, nine biosafety level-III laboratories, five new regional national centre for disease control will be set up.\n",
        "'''\n",
        "tr=TextRank4Keyword()\n",
        "tr.analyze(text, candidate_pos = ['NOUN', 'PROPN'], window_size=4, lower=False)\n",
        "tr.get_keywords(10)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "health - 2.841356677466052\n",
            "care - 1.939419843626815\n",
            "country - 1.7942668856339528\n",
            "healthcare - 1.7361309140956975\n",
            "infrastructure - 1.7069148707640296\n",
            "laboratories - 1.6792358268334229\n",
            "services - 1.6618475644014108\n",
            "Health - 1.4379300022893773\n",
            "constituency - 1.4240540436860147\n",
            "districts - 1.3674166586618508\n",
            "Ayushman - 1.3040098773911275\n",
            "Bharat - 1.2888257923789173\n"
          ]
        }
      ]
    }
  ]
}